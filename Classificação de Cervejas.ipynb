{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso! 26449 linhas carregadas.\n"
     ]
    }
   ],
   "source": [
    "beer = pd.DataFrame(pd.read_csv(\"beerData.csv\"), \n",
    "                                   columns=['Style','Size(L)','OG','FG','ABV','IBU',\n",
    "                                            'Color','BoilSize','BoilTime','Efficiency'])\n",
    "\n",
    "n_beer = beer.shape[0]\n",
    "\n",
    "## Código dos estilos de Cervejas\n",
    "## 1 - American IPA\n",
    "## 2 - American Amber Ale\n",
    "## 3 - American Light Lager\n",
    "## 4 - American Pale Ale\n",
    "## 5 - Saison\n",
    "\n",
    "print(\"Arquivo carregado com sucesso! {} linhas carregadas.\".format(n_beer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas features: ['Size(L)', 'OG', 'FG', 'ABV', 'IBU', 'Color', 'BoilSize', 'BoilTime', 'Efficiency']\n",
      "Coluna farget: Style\n",
      "   Size(L)     OG     FG   ABV     IBU  Color  BoilSize  BoilTime  Efficiency\n",
      "0    18.93  1.063  1.018  5.91   59.25   8.98     22.71        60        70.0\n",
      "1    22.71  1.061  1.017  5.80   54.48   8.50     26.50        60        70.0\n",
      "2    24.61  1.055  1.013  5.58   40.12   8.00     29.34        70        79.0\n",
      "3    25.00  1.064  1.014  6.63   64.26   7.78     29.00        90        74.0\n",
      "4    15.14  1.066  1.015  6.62  111.00  14.26     11.36        90        70.0\n"
     ]
    }
   ],
   "source": [
    "#Definindo as colunas feature(X) e target (y)\n",
    "features_col = list(beer.columns[1:12])\n",
    "target_col = beer.columns[0]\n",
    "print(\"Colunas features: {}\".format(features_col))\n",
    "print(\"Coluna farget: {}\".format(target_col))\n",
    "\n",
    "X_all = beer[features_col]\n",
    "y_all = beer[target_col]\n",
    "\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o tamanho da base que será destinada para treino e efetuando o treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando DecisionTreeClassifier...\n",
      "Feito!\n",
      "Treinado em 0.230 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo DecisionTreeClassifier\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando DecisionTreeClassifier.\n",
      "Feito!\n",
      "A previsão demorou 0.009 (secs).\n",
      "F1 score para o treinamento foi: 0.9999691091471454\n"
     ]
    }
   ],
   "source": [
    "# Prevendo e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando DecisionTreeClassifier.\n",
      "Feito!\n",
      "A previsão demorou 0.005 (secs).\n",
      "F1 score for test set: 0.4882691673994799\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando SVC...\n",
      "Feito!\n",
      "Treinado em 92.589 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo utilizando SVC()\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "    \n",
    "clf = SVC()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando SVC.\n",
      "Feito!\n",
      "A previsão demorou 18.190 (secs).\n",
      "F1 score para o treinamento foi: 0.8766165501426508\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando SVC.\n",
      "Feito!\n",
      "A previsão demorou 7.760 (secs).\n",
      "F1 score for test set: 0.4074360183437853\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando GaussianNB...\n",
      "Feito!\n",
      "Treinado em 0.014 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo utilizando GaussianNB\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "    \n",
    "clf =  GaussianNB()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando GaussianNB.\n",
      "Feito!\n",
      "A previsão demorou 0.024 (secs).\n",
      "F1 score para o treinamento foi: 0.42573700821856725\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando GaussianNB.\n",
      "Feito!\n",
      "A previsão demorou 0.008 (secs).\n",
      "F1 score for test set: 0.40847269365367406\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
