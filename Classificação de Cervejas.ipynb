{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leand\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo carregado com sucesso! 26449 linhas carregadas.\n"
     ]
    }
   ],
   "source": [
    "beer = pd.DataFrame(pd.read_csv(\"beerData.csv\"), \n",
    "                                   columns=['Style','Size(L)','OG','FG','ABV','IBU',\n",
    "                                            'Color','BoilSize','BoilTime','Efficiency'])\n",
    "\n",
    "n_beer = beer.shape[0]\n",
    "\n",
    "## Código dos estilos de Cervejas\n",
    "## 1 - American IPA\n",
    "## 2 - American Amber Ale\n",
    "## 3 - American Light Lager\n",
    "## 4 - American Pale Ale\n",
    "## 5 - Saison\n",
    "\n",
    "print(\"Arquivo carregado com sucesso! {} linhas carregadas.\".format(n_beer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas features: ['Size(L)', 'OG', 'FG', 'ABV', 'IBU', 'Color', 'BoilSize', 'BoilTime', 'Efficiency']\n",
      "Coluna farget: Style\n",
      "   Size(L)     OG     FG   ABV     IBU  Color  BoilSize  BoilTime  Efficiency\n",
      "0    18.93  1.063  1.018  5.91   59.25   8.98     22.71        60        70.0\n",
      "1    22.71  1.061  1.017  5.80   54.48   8.50     26.50        60        70.0\n",
      "2    24.61  1.055  1.013  5.58   40.12   8.00     29.34        70        79.0\n",
      "3    25.00  1.064  1.014  6.63   64.26   7.78     29.00        90        74.0\n",
      "4    15.14  1.066  1.015  6.62  111.00  14.26     11.36        90        70.0\n"
     ]
    }
   ],
   "source": [
    "#Definindo as colunas feature(X) e target (y)\n",
    "features_col = list(beer.columns[1:12])\n",
    "target_col = beer.columns[0]\n",
    "print(\"Colunas features: {}\".format(features_col))\n",
    "print(\"Coluna farget: {}\".format(target_col))\n",
    "\n",
    "X_all = beer[features_col]\n",
    "y_all = beer[target_col]\n",
    "\n",
    "print(X_all.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo o tamanho da base que será destinada para treino e efetuando o treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando DecisionTreeClassifier...\n",
      "Feito!\n",
      "Treinado em 0.246 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo DecisionTreeClassifier\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando DecisionTreeClassifier.\n",
      "Feito!\n",
      "A previsão demorou 0.011 (secs).\n",
      "F1 score para o treinamento foi: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Prevendo e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando DecisionTreeClassifier.\n",
      "Feito!\n",
      "A previsão demorou 0.005 (secs).\n",
      "F1 score for test set: 0.4999737950306063\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando SVC...\n",
      "Feito!\n",
      "Treinado em 89.042 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo utilizando SVC()\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "    \n",
    "clf = SVC()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando SVC.\n",
      "Feito!\n",
      "A previsão demorou 18.039 (secs).\n",
      "F1 score para o treinamento foi: 0.8794107605079292\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando SVC.\n",
      "Feito!\n",
      "A previsão demorou 7.753 (secs).\n",
      "F1 score for test set: 0.4061796012627864\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando GaussianNB...\n",
      "Feito!\n",
      "Treinado em 0.018 (secs)\n"
     ]
    }
   ],
   "source": [
    "# Treinando o modelo utilizando GaussianNB\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print(\"Treinando {}...\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nTreinado em {:.3f} (secs)\".format(end - start))\n",
    "    #return end - start\n",
    "    \n",
    "clf =  GaussianNB()\n",
    "\n",
    "# Treinando o modelo\n",
    "train_classifier(clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando GaussianNB.\n",
      "Feito!\n",
      "A previsão demorou 0.028 (secs).\n",
      "F1 score para o treinamento foi: 0.4496082914950934\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição e calculando a F1 score\n",
    "# A F-score é uma medida de precisão de um teste. Quanto mais próximo de 1 melhor e quanto mais perto de 0 pior.\n",
    "\n",
    "def predict_labels(clf, features, target):\n",
    "    print(\"Prevendo utilizando {}.\".format(clf.__class__.__name__))\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    print(\"Feito!\\nA previsão demorou {:.3f} (secs).\".format(end - start))\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "train_f1_score = predict_labels(clf, X_train, y_train)\n",
    "print(\"F1 score para o treinamento foi: {}\".format(train_f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prevendo utilizando GaussianNB.\n",
      "Feito!\n",
      "A previsão demorou 0.010 (secs).\n",
      "F1 score for test set: 0.44765359525962295\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a predição nos dados de teste\n",
    "print(\"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
